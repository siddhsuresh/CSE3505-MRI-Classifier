{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7_Rm5H74zw_"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install imutils\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "keHB3xiNHkFJ",
        "outputId": "aa7df506-992a-4fa6-b2f8-2301160196d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All modules have been imported\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import scipy\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tensorflow.keras.utils import *\n",
        "# import pydot\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from skimage.io import *\n",
        "%config Completer.use_jedi = False\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras import layers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "RANDOM_SEED = 123\n",
        "\n",
        "print(\"All modules have been imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxpXo_cnHv3H",
        "outputId": "8cfc74da-5911-47d0-c85b-677b2c8f2b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\n",
            "├── sample_data\n",
            "├── TEST\n",
            "│   ├── NO\n",
            "│   └── YES\n",
            "├── TRAIN\n",
            "│   ├── NO\n",
            "│   └── YES\n",
            "└── VAL\n",
            "    ├── NO\n",
            "    └── YES\n",
            "\n",
            "10 directories\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tree\n",
        "clear_output()\n",
        "# create new folders\n",
        "!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO\n",
        "!tree -d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "gWxWxGNCQnfJ",
        "outputId": "4375fb4b-623b-41d6-890d-85244e9422ec"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-92fb86673630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Brain_Tumor_Detection/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mephemeral\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       readonly=readonly)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 125\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Brain_Tumor_Detection/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYlAgLf2H5bG"
      },
      "outputs": [],
      "source": [
        "IMG_PATH = \"../content/Brain_Tumor_Detection/MyDrive/certificates/Brain_Tumor_Detection\"\n",
        "\n",
        "# split the data by train/val/test\n",
        "ignored = {\"pred\"}\n",
        "# split the data by train/val/test\n",
        "for CLASS in os.listdir(IMG_PATH):\n",
        "    if CLASS not in ignored:\n",
        "        if not CLASS.startswith('.'):\n",
        "            IMG_NUM = len(os.listdir(IMG_PATH +\"/\"+ CLASS))\n",
        "            for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH +\"/\"+ CLASS)):\n",
        "                img = IMG_PATH+ '/' +  CLASS + '/' + FILE_NAME\n",
        "                if n < 300:\n",
        "                    shutil.copy(img, 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n",
        "                elif n < 0.8*IMG_NUM:\n",
        "                    shutil.copy(img, 'TRAIN/'+ CLASS.upper() + '/' + FILE_NAME)\n",
        "                else:\n",
        "                    shutil.copy(img, 'VAL/'+ CLASS.upper() + '/' + FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUyjj0GaTZSm"
      },
      "outputs": [],
      "source": [
        "def load_data(dir_path, img_size=(100,100)):\n",
        "    \"\"\"\n",
        "    Load resized images as np.arrays to workspace\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    i = 0\n",
        "    labels = dict()\n",
        "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
        "        if not path.startswith('.'):\n",
        "            labels[i] = path\n",
        "            for file in os.listdir(dir_path + path):\n",
        "                if not file.startswith('.'):\n",
        "                    img = cv2.imread(dir_path + path + '/' + file)\n",
        "                    X.append(img)\n",
        "                    y.append(i)\n",
        "            i += 1\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
        "    return X, y, labels\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MRNzC_4Tbf1"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = 'TRAIN/'\n",
        "TEST_DIR = 'TEST/'\n",
        "VAL_DIR = 'VAL/'\n",
        "IMG_SIZE = (224,224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wIPwz5-TfpO"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\n",
        "X_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\n",
        "X_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLWf5ObTTpVI"
      },
      "outputs": [],
      "source": [
        "y = dict()\n",
        "y[0] = []\n",
        "y[1] = []\n",
        "for set_name in (y_train, y_val, y_test):\n",
        "    y[0].append(np.sum(set_name == 0))\n",
        "    y[1].append(np.sum(set_name == 1))\n",
        "\n",
        "trace0 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[0],\n",
        "    name='No',\n",
        "    marker=dict(color='#33cc33'),\n",
        "    opacity=0.7\n",
        ")\n",
        "trace1 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[1],\n",
        "    name='Yes',\n",
        "    marker=dict(color='#ff3300'),\n",
        "    opacity=0.7\n",
        ")\n",
        "data = [trace0, trace1]\n",
        "layout = go.Layout(\n",
        "    title='Count of classes in each set',\n",
        "    xaxis={'title': 'Set'},\n",
        "    yaxis={'title': 'Count'}\n",
        ")\n",
        "fig = go.Figure(data, layout)\n",
        "iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaHB0M8WTwnY"
      },
      "outputs": [],
      "source": [
        "def plot_samples(X, y, labels_dict, n=50):\n",
        "    \"\"\"\n",
        "    Creates a gridplot for desired number of images (n) from the specified set\n",
        "    \"\"\"\n",
        "    for index in range(len(labels_dict)):\n",
        "        imgs = X[np.argwhere(y == index)][:n]\n",
        "        j = 10\n",
        "        i = int(n/j)\n",
        "\n",
        "        plt.figure(figsize=(15,6))\n",
        "        c = 1\n",
        "        for img in imgs:\n",
        "            plt.subplot(i,j,c)\n",
        "            plt.imshow(img[0])\n",
        "\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            c += 1\n",
        "        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leyEC2xBT24o"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train, y_train, labels, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnlWBsHqT68Z"
      },
      "outputs": [],
      "source": [
        "def crop_imgs(set_name, add_pixels_value=0):\n",
        "    \"\"\"\n",
        "    Finds the extreme points on the image and crops the rectangular out of them\n",
        "    \"\"\"\n",
        "    set_new = []\n",
        "    for img in set_name:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # threshold the image, then perform a series of erosions +\n",
        "        # dilations to remove any small regions of noise\n",
        "        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "        thresh = cv2.erode(thresh, None, iterations=2)\n",
        "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "        # find contours in thresholded image, then grab the largest one\n",
        "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cnts = imutils.grab_contours(cnts)\n",
        "        c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "        # find the extreme points\n",
        "        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "        extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "        extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "        extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\n",
        "        ADD_PIXELS = add_pixels_value\n",
        "        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "        set_new.append(new_img)\n",
        "\n",
        "    return np.array(set_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZudLR8EWiXe"
      },
      "outputs": [],
      "source": [
        "import imutils\n",
        "img = cv2.imread('./VAL/NO/no115.jpg')\n",
        "img = cv2.resize(\n",
        "            img,\n",
        "            dsize=IMG_SIZE,\n",
        "            interpolation=cv2.INTER_CUBIC\n",
        "        )\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# threshold the image, then perform a series of erosions +\n",
        "# dilations to remove any small regions of noise\n",
        "thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "thresh = cv2.erode(thresh, None, iterations=2)\n",
        "thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "# find contours in thresholded image, then grab the largest one\n",
        "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "# find the extreme points\n",
        "extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\n",
        "# add contour on the image\n",
        "img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n",
        "\n",
        "# add extreme points\n",
        "img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n",
        "img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n",
        "img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n",
        "img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n",
        "\n",
        "# crop\n",
        "ADD_PIXELS = 0\n",
        "new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OixL657CWwEt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(141)\n",
        "plt.imshow(img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Step 1. Get the original image')\n",
        "plt.subplot(142)\n",
        "plt.imshow(img_cnt)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Step 2. Find the biggest contour')\n",
        "plt.subplot(143)\n",
        "plt.imshow(img_pnt)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Step 3. Find the extreme points')\n",
        "plt.subplot(144)\n",
        "plt.imshow(new_img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Step 4. Crop the image')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2lZhT07W09u"
      },
      "outputs": [],
      "source": [
        "X_train_crop = crop_imgs(set_name=X_train)\n",
        "X_val_crop = crop_imgs(set_name=X_val)\n",
        "X_test_crop = crop_imgs(set_name=X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgnl3BNyW7DA"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train_crop, y_train, labels, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMRlxR8BW_KZ"
      },
      "outputs": [],
      "source": [
        "def save_new_images(x_set, y_set, folder_name):\n",
        "    i = 0\n",
        "    for (img, imclass) in zip(x_set, y_set):\n",
        "        if imclass == 0:\n",
        "            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)\n",
        "        else:\n",
        "            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6syJYkhRXGU9"
      },
      "outputs": [],
      "source": [
        "# saving new images to the folder\n",
        "!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO\n",
        "\n",
        "save_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\n",
        "save_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\n",
        "save_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfVEZfYZXJk3"
      },
      "outputs": [],
      "source": [
        "def preprocess_imgs(set_name, img_size):\n",
        "    set_new = []\n",
        "    for img in set_name:\n",
        "        img = cv2.resize(\n",
        "            img,\n",
        "            dsize=img_size,\n",
        "            interpolation=cv2.INTER_CUBIC\n",
        "        )\n",
        "        set_new.append(preprocess_input(img))\n",
        "    return np.array(set_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkGtwRcdXMkU"
      },
      "outputs": [],
      "source": [
        "X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\n",
        "X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\n",
        "X_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8FbDI7OXRft"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train_prep, y_train, labels, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phCp9jgVXXt5"
      },
      "outputs": [],
      "source": [
        "demo_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.05,\n",
        "    brightness_range=[0.1, 1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "os.mkdir('preview')\n",
        "x = X_train_crop[0]  \n",
        "x = x.reshape((1,) + x.shape) \n",
        "\n",
        "i = 0\n",
        "for batch in demo_datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='aug_img', save_format='jpg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break \n",
        "        \n",
        "plt.imshow(X_train_crop[0])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "i = 1\n",
        "for img in os.listdir('preview/'):\n",
        "    img = cv2.imread('preview/' + img)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(3,7,i)\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    i += 1\n",
        "    if i > 3*7:\n",
        "        break\n",
        "plt.suptitle('Augemented Images')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mIZGZ0gX83r"
      },
      "outputs": [],
      "source": [
        "!rm -rf preview/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZjsPE4oYDQZ"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = 'TRAIN_CROP/'\n",
        "VAL_DIR = 'VAL_CROP/'\n",
        "RANDOM_SEED = 42\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8LB4hyxYIcC"
      },
      "outputs": [],
      "source": [
        "base_Neural_Net= ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "model=Sequential()\n",
        "model.add(base_Neural_Net)\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "for layer in base_Neural_Net.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "    \n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy' , 'AUC']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eopq_lveYSj_"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 15\n",
        "es = EarlyStopping(\n",
        "    monitor='val_acc', \n",
        "    mode='max',\n",
        "    patience=6\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=15,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=25,\n",
        "    callbacks=[es]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "ir1Iyys-Z3Em",
        "outputId": "72e3e8e0-49fe-4ea1-caad-f9e8ef8a4f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 337s 6s/step\n",
            "Train Accuracy = 1.00\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = model.predict(X_train_prep)\n",
        "predictions = [1 if x>0.5 else 0 for x in predictions]\n",
        "\n",
        "accuracy = accuracy_score(y_train, predictions)\n",
        "print('Train Accuracy = %.2f' % accuracy)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_train, predictions) \n",
        "cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYaVPH5jZ6yf"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_val_prep)\n",
        "predictions = [1 if x>0.5 else 0 for x in predictions]\n",
        "\n",
        "accuracy = accuracy_score(y_val, predictions)\n",
        "print('Val Accuracy = %.2f' % accuracy)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_val, predictions) \n",
        "cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ4b6-FoZ9WK"
      },
      "outputs": [],
      "source": [
        "# validate on test set\n",
        "predictions = model.predict(X_test_prep)\n",
        "predictions = [1 if x>0.5 else 0 for x in predictions]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print('Test Accuracy = %.2f' % accuracy)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_test, predictions) \n",
        "cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6mfEwYEZ_wm"
      },
      "outputs": [],
      "source": [
        "prob_pred = model.predict(X_test_prep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8d_ptYpaBN2",
        "outputId": "6f643c76-75a1-407f-8d4a-109923401711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score is : 0.92\n",
            "Precision score is : 0.9212\n",
            "Recall score is : 0.92\n",
            "F1 Score is : 0.9199\n",
            "ROC AUC Score is : 0.9831\n",
            "Cohen Kappa Score: 0.84\n",
            "\t\tClassification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.92       300\n",
            "           1       0.90      0.95      0.92       300\n",
            "\n",
            "    accuracy                           0.92       600\n",
            "   macro avg       0.92      0.92      0.92       600\n",
            "weighted avg       0.92      0.92      0.92       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print('Accuracy score is :', np.round(metrics.accuracy_score(y_test, predictions),4))\n",
        "print('Precision score is :', np.round(metrics.precision_score(y_test, predictions, average='weighted'),4))\n",
        "print('Recall score is :', np.round(metrics.recall_score(y_test, predictions, average='weighted'),4))\n",
        "print('F1 Score is :', np.round(metrics.f1_score(y_test, predictions, average='weighted'),4))\n",
        "print('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test, prob_pred,multi_class='ovo', average='weighted'),4))\n",
        "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, predictions),4))\n",
        "\n",
        "print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kehc1w2CmGMe"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
